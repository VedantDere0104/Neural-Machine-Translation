{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_With_Transformer_Multi30k.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RZzGcSHgxy_o2Z4OxTqJ6kIxFV4wtMIw",
      "authorship_tag": "ABX9TyNaX0fBh9YO7AFd3rI/QU5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantDere0104/Neural-Machine-Translation/blob/main/NMT_With_Transformer_Multi30k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJUnNU2h_akp"
      },
      "source": [
        "####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls1mcMk1_d1L"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torchtext\r\n",
        "from torchtext.data import Field  , BucketIterator\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "import spacy\r\n",
        "from tqdm.auto import tqdm\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "import nltk\r\n",
        "from nltk.translate.bleu_score import corpus_bleu\r\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H13SvFcz_tx9"
      },
      "source": [
        "! python -m spacy download de"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMu769oP_0Lg"
      },
      "source": [
        "spacy_ger = spacy.load('de')\r\n",
        "spacy_eng = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f179iEBIAC8b"
      },
      "source": [
        "def tokenizer_ger(text):\r\n",
        "  return [tok.text for tok in spacy_ger.tokenizer(text)]\r\n",
        "def tokenizer_eng(text):\r\n",
        "  return [tok.text for tok in spacy_eng.tokenizer(text)]\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clGUiy5UAWJ5"
      },
      "source": [
        "german = Field(tokenize=tokenizer_ger , init_token='<SOS>' , eos_token='<EOS>' , )\r\n",
        "english = Field(tokenize= tokenizer_eng , init_token='<SOS>' , eos_token='<EOS>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_pe7npQApxJ"
      },
      "source": [
        "train_data , validation_data , test_data = Multi30k.splits(exts=('.de' , '.en') , \r\n",
        "                                                           fields = (german , english) , )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiiox7fDA1Ru"
      },
      "source": [
        "german.build_vocab(train_data)\r\n",
        "english.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvSXTyYes4Pq"
      },
      "source": [
        "class PositionalEncoder(nn.Module):\r\n",
        "  def __init__(self, d_model, max_seq_len = 80):\r\n",
        "    super().__init__()\r\n",
        "    self.d_model = d_model\r\n",
        "    \r\n",
        "    # create constant 'pe' matrix with values dependant on \r\n",
        "    # pos and i\r\n",
        "    self.pe = torch.zeros(max_seq_len, d_model)\r\n",
        "    for pos in range(max_seq_len):\r\n",
        "        for i in range(0, d_model, 2):\r\n",
        "            self.pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\r\n",
        "            self.pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\r\n",
        "            \r\n",
        "    self.pe = self.pe.unsqueeze(0)\r\n",
        "\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    # make embeddings relatively larger\r\n",
        "    x = x * math.sqrt(self.d_model)\r\n",
        "    #add constant to embedding\r\n",
        "    seq_len = x.size(1)\r\n",
        "    x = torch.tensor(self.pe[:,:seq_len] , requires_grad=False).cuda()\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlvW3lxwA9iY"
      },
      "source": [
        "class Transformer(nn.Module):\r\n",
        "  def __init__(\r\n",
        "    self,\r\n",
        "    embedding_size,\r\n",
        "    src_vocab_size,\r\n",
        "    trg_vocab_size,\r\n",
        "    src_pad_idx,\r\n",
        "    num_heads,\r\n",
        "    num_encoder_layers,\r\n",
        "    num_decoder_layers,\r\n",
        "    forward_expansion,\r\n",
        "    dropout,\r\n",
        "    max_len,\r\n",
        "    device,\r\n",
        "  ):\r\n",
        "    super(Transformer, self).__init__()\r\n",
        "    self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\r\n",
        "    #self.src_position_embedding = nn.Embedding(max_len, embedding_size)\r\n",
        "    self.src_position_embedding = PositionalEncoder(embedding_size)\r\n",
        "    self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\r\n",
        "    #self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\r\n",
        "    self.trg_position_embedding = PositionalEncoder(embedding_size)\r\n",
        "\r\n",
        "    self.device = device\r\n",
        "    self.transformer = nn.Transformer(\r\n",
        "        embedding_size,\r\n",
        "        num_heads,\r\n",
        "        num_encoder_layers,\r\n",
        "        num_decoder_layers,\r\n",
        "        forward_expansion,\r\n",
        "        dropout,\r\n",
        "    )\r\n",
        "    self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "    self.src_pad_idx = src_pad_idx\r\n",
        "    self.out = nn.Linear(trg_vocab_size , trg_vocab_size)\r\n",
        "    self.relu = nn.ReLU(inplace = True)\r\n",
        "\r\n",
        "\r\n",
        "  def make_src_mask(self, src):\r\n",
        "    src_mask = src.transpose(0, 1) == self.src_pad_idx\r\n",
        "\r\n",
        "    # (N, src_len)\r\n",
        "    return src_mask.to(self.device)\r\n",
        "\r\n",
        "  def forward(self, src, trg):\r\n",
        "    src_seq_length, N = src.shape\r\n",
        "    trg_seq_length, N = trg.shape\r\n",
        "\r\n",
        "    src_positions = (\r\n",
        "        torch.arange(0, src_seq_length)\r\n",
        "        .unsqueeze(1)\r\n",
        "        .expand(src_seq_length, N)\r\n",
        "        .to(self.device)\r\n",
        "    )\r\n",
        "\r\n",
        "    trg_positions = (\r\n",
        "        torch.arange(0, trg_seq_length)\r\n",
        "        .unsqueeze(1)\r\n",
        "        .expand(trg_seq_length, N)\r\n",
        "        .to(self.device)\r\n",
        "    )\r\n",
        "\r\n",
        "    embed_src = self.dropout(\r\n",
        "        (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\r\n",
        "    )\r\n",
        "    embed_trg = self.dropout(\r\n",
        "        (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\r\n",
        "    )\r\n",
        "\r\n",
        "    src_padding_mask = self.make_src_mask(src)\r\n",
        "    trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\r\n",
        "        self.device\r\n",
        "    )\r\n",
        "\r\n",
        "    out = self.transformer(\r\n",
        "        embed_src,\r\n",
        "        embed_trg,\r\n",
        "        src_key_padding_mask=src_padding_mask,\r\n",
        "        tgt_mask=trg_mask,\r\n",
        "    )\r\n",
        "    out = self.out(self.fc_out(out))\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbGYKT0FEfEv"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "num_epochs = 300\r\n",
        "learning_rate = 0.00001\r\n",
        "batch_size = 32\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYIvHuMpN7O9"
      },
      "source": [
        "def save_checkpoint(state, filename=\"/content/drive/MyDrive/checkpoint_NMT_Multi30k.pth.tar\"):\r\n",
        "    print(\"=> Saving checkpoint\")\r\n",
        "    torch.save(state, filename)\r\n",
        "\r\n",
        "\r\n",
        "def load_checkpoint(checkpoint, model, optimizer):\r\n",
        "    print(\"=> Loading checkpoint\")\r\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\r\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5VHD8meGtiJ"
      },
      "source": [
        "src_vocab_size = len(german.vocab)\r\n",
        "trg_vocab_size = len(english.vocab)\r\n",
        "embed_size = 512 \r\n",
        "heads = 8\r\n",
        "num_encoder_layer = 6\r\n",
        "num_decoder_layer = 6\r\n",
        "dropout = 0.10\r\n",
        "max_len = 100\r\n",
        "forward_expansion = 4\r\n",
        "src_pad_index = german.vocab.stoi['<PAD>']\r\n",
        "betas = (0.9 , 0.98)\r\n",
        "save_model = True\r\n",
        "load_model = True\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9fqzlnCOE9J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25QM0k7nHZwt"
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, validation_data, test_data),\r\n",
        "    batch_size=batch_size,\r\n",
        "    sort_within_batch=True,\r\n",
        "    sort_key=lambda x: len(x.src),\r\n",
        "    device=device,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpX-El0pHxA7"
      },
      "source": [
        "for batch in train_iterator:\r\n",
        "  print(batch.src.shape , batch.trg.shape)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8lJpLSxH-oC"
      },
      "source": [
        "model = Transformer(\r\n",
        "    embed_size , \r\n",
        "    src_vocab_size , \r\n",
        "    trg_vocab_size , \r\n",
        "    src_pad_index , \r\n",
        "    heads , \r\n",
        "    num_encoder_layer , \r\n",
        "    num_decoder_layer , \r\n",
        "    forward_expansion , \r\n",
        "    dropout ,\r\n",
        "    max_len , \r\n",
        "    device\r\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFe0Ftg4Ie0i"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters() , lr = learning_rate , betas = betas )\r\n",
        "pad_index = english.vocab.stoi['<PAD>']\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_index)\r\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\r\n",
        "    optimizer, factor=0.1, patience=10, verbose=True\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3dvEG4PfJDD"
      },
      "source": [
        "for epoch in range(num_epochs):\r\n",
        "  print(f'[Epoch {epoch + 1} / {num_epochs}]')\r\n",
        "  if save_model:\r\n",
        "    checkpoint = {\r\n",
        "        \"state_dict\": model.state_dict(),\r\n",
        "        \"optimizer\": optimizer.state_dict(),\r\n",
        "        }\r\n",
        "    save_checkpoint(checkpoint)\r\n",
        "\r\n",
        "\r\n",
        "  losses = []\r\n",
        "  losses_valid = []\r\n",
        "  for batch_idx, batch in enumerate(tqdm(train_iterator)):\r\n",
        "\r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    inp_data = batch.src.to(device)\r\n",
        "    target = batch.trg.to(device)\r\n",
        "    \r\n",
        "    output = model(inp_data, target[:-1, :]).to(device)\r\n",
        "\r\n",
        "    output = output.reshape(-1, output.shape[2])\r\n",
        "    target = target[1:].reshape(-1)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    loss = criterion(output, target)\r\n",
        "    losses.append(loss.item())\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.5)\r\n",
        "    \r\n",
        "\r\n",
        " \r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "    for batch_idx , batch_valid in enumerate(valid_iterator):\r\n",
        "      inp_data_valid =  batch_valid.src.to(device)\r\n",
        "      target_data_valid = batch_valid.trg.to(device)\r\n",
        "      model_prediction = model(inp_data_valid , target_data_valid[:-1 , :])\r\n",
        "      model_prediction = model_prediction.reshape(-1, model_prediction.shape[2])\r\n",
        "      target_data_valid = target_data_valid[1:].reshape(-1)\r\n",
        "\r\n",
        "      loss_valid = criterion(model_prediction , target_data_valid)\r\n",
        "      losses_valid.append(loss_valid)\r\n",
        "      \r\n",
        "  model.train()\r\n",
        "\r\n",
        "  mean_loss = sum(losses) / len(losses)\r\n",
        "  mean_loss_valid = sum(losses_valid) / len(losses_valid)\r\n",
        "\r\n",
        "  print(f'[Loss => {mean_loss} ------ Validation_loss => {mean_loss_valid} ]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmABMh_WKYsI"
      },
      "source": [
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\r\n",
        "  # Load german tokenizer\r\n",
        "  #spacy_ger = spacy.load(\"de\")\r\n",
        "\r\n",
        "  # Create tokens using spacy and everything in lower case (which is what our vocab is)\r\n",
        "  if type(sentence) == str:\r\n",
        "    tokens = [token.text.lower() for token in spacy_ger(sentence)]\r\n",
        "  else:\r\n",
        "    tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "  # Add <SOS> and <EOS> in beginning and end respectively\r\n",
        "  tokens.insert(0, german.init_token)\r\n",
        "  tokens.append(german.eos_token)\r\n",
        "\r\n",
        "  # Go through each german token and convert to an index\r\n",
        "  text_to_indices = [german.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "  # Convert to Tensor\r\n",
        "  sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "  outputs = [english.vocab.stoi[\"<sos>\"]]\r\n",
        "  for i in range(max_length):\r\n",
        "    trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      output = model(sentence_tensor, trg_tensor)\r\n",
        "\r\n",
        "    best_guess = output.argmax(2)[-1, :].item()\r\n",
        "    outputs.append(best_guess)\r\n",
        "\r\n",
        "    if best_guess == english.vocab.stoi[\"<eos>\"]:\r\n",
        "      break\r\n",
        "\r\n",
        "  translated_sentence = [english.vocab.itos[idx] for idx in outputs]\r\n",
        "  # remove start token\r\n",
        "  return translated_sentence[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8JFISUBK7rx"
      },
      "source": [
        "def bleu(data, model, german, english, device):\r\n",
        "  targets = []\r\n",
        "  outputs = []\r\n",
        "\r\n",
        "  for example in tqdm(data):\r\n",
        "    src = vars(example)[\"src\"]\r\n",
        "    trg = vars(example)[\"trg\"]\r\n",
        "\r\n",
        "    prediction = translate_sentence(model, src, german, english, device)\r\n",
        "    prediction = prediction[:-1]  # remove <eos> token\r\n",
        "\r\n",
        "    targets.append([trg])\r\n",
        "    outputs.append(prediction)\r\n",
        "\r\n",
        "  return corpus_bleu(targets , outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQwZEK6FowgP"
      },
      "source": [
        "bleu(test_data , model , english , german , device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OISyuH9Jhsbo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}